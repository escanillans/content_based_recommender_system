{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Recommender System\n",
    "\n",
    "- In this demo I will create a content-based recommender system\n",
    "- This revolves around the following key ideas (typically used in Data Science):\n",
    "    1. Vectors\n",
    "    2. TF-IDF\n",
    "    3. Cosine Similarity\n",
    "   \n",
    "## Vectors:\n",
    "- Input: text/words\n",
    "- Output: text/words represented in a vector space model\n",
    "- Note: this idea seems pretty 'bland' however this process is the reason why we're able to make great strides in ML and AI.\n",
    "\n",
    "## TF-IDF:\n",
    "- TF-IDF stands for Term Frequency and Inverse Document Frequency.\n",
    "- Use this to help determine the importance of a word in a document.\n",
    "- I won't go into detail, but here are the general steps of TF-IDF:\n",
    "    1. Create a dictionary of words (bag of words) present in the whole document space (a document space is basically the data you have...it's a list of documents).\n",
    "    2. Form your vector: based on your bag of words, count the presence or absence  of word by marking it (1=present, 0=absent). For each document, you know get your vector.\n",
    "    3. Compute TF-IDF (can look up equation in Wikipedia if you'd like).\n",
    "\n",
    "## Cosine Similarity:\n",
    "- Cosine similarity computes how similar two non-zero vectors are...the vectors in this case are the same vectors previously mentioned.\n",
    "- If two vectors make an angle $0$, then we know that $cos(0)=1$, and this means that the sentences are closely related.\n",
    "- If two vectors are orthogonal ($cos(90)$), then the sentences are almost unrelated.\n",
    "\n",
    "That's enough explaining...let me show you how this would be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "- Here is some synthetic data I made. It's just a list of book titles about machine learning.\n",
    "- Task: Recommend a book to me based on other book titles\n",
    "- The dataset is called books.csv\n",
    "- Key assumption: \n",
    "    - The book titles are detailed enough to explain what it is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Book Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Probabilistic Graphical Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bayesian Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Doing data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Pattern Recognition and Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Elements of Statistical Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>An introduction to Statistical Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Python Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Natural Langauage Processing with Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Statistical Distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Monte Carlo Statistical Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Machine Learning :A Probablisitic Perspective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Neural Network Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Matrix methods in Data Mining and Pattern reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Statistical Power Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Probability Theory The Logic of Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Introduction to Probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Statistical methods for recommender systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Entropy and Information theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Clever Algorithms: Nature-Inspired Programming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Precision: Principles, Practices and Solutions...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                         Book Title\n",
       "0    1                     Probabilistic Graphical Models\n",
       "1    2                            Bayesian Data Analysis \n",
       "2    3                                Doing data science \n",
       "3    4          Pattern Recognition and Machine Learning \n",
       "4    5              The Elements of Statistical Learning \n",
       "5    6           An introduction to Statistical Learning \n",
       "6    7                           Python Machine Learning \n",
       "7    8           Natural Langauage Processing with Python\n",
       "8    9                          Statistical Distributions\n",
       "9   10                    Monte Carlo Statistical Methods\n",
       "10  11      Machine Learning :A Probablisitic Perspective\n",
       "11  12                             Neural Network Design \n",
       "12  13  Matrix methods in Data Mining and Pattern reco...\n",
       "13  14                         Statistical Power Analysis\n",
       "14  15            Probability Theory The Logic of Science\n",
       "15  16                       Introduction to Probability \n",
       "16  17        Statistical methods for recommender systems\n",
       "17  18                     Entropy and Information theory\n",
       "18  19  Clever Algorithms: Nature-Inspired Programming...\n",
       "19  20  Precision: Principles, Practices and Solutions..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in dataset\n",
    "df = pd.read_csv(\"data/books.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute word n-grams\n",
    "\n",
    "- Again, without loss of generality and without losing focus on the main subject, I'll explain n-gram briefly.\n",
    "- ngram(1,3) takes into account 1-gram, 2-gram, and 3-gram.\n",
    "- e.g. Let the sentence be \"I like basketball\"\n",
    "    - ngram(1,3) = {'I', 'like', 'basketball', 'I like', 'like basketball', 'I like basketball'}\n",
    "    - i.e. it's every possible combination (order matters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object to convert collection of raw text docs to a matrix of TF-IDF features\n",
    "tf = TfidfVectorizer(analyzer = 'word', ngram_range=(1,3),\n",
    "                    min_df = 0, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn vocab and idf, return term-doc matrix\n",
    "tfidf_matrix = tf.fit_transform(df['Book Title'])\n",
    "\n",
    "# compute similarities\n",
    "cos_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results as a dictionary\n",
    "results = {}\n",
    "\n",
    "# go through each row of df\n",
    "for idx, row in df.iterrows():\n",
    "    # store similar ids based on cosine similarity, then sort in ascending order\n",
    "    similar_indices = cos_sim[idx].argsort()[::-1]\n",
    "    \n",
    "    # get 5 most similar books\n",
    "    similar_items = [(cos_sim[idx][i], df['ID'][i]) for i in similar_indices]\n",
    "    results[row['ID']] = similar_items[1:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is going to return a row that mathches the id\n",
    "# along with the book title as a list (not as a dataframe)\n",
    "def item(id):\n",
    "    return df.loc[df['ID'] == id]['Book Title'].tolist()[0]\n",
    "\n",
    "# this function returns the most similar books\n",
    "# input: id = id of the book, num = number of similar books to return\n",
    "# output: most similar books\n",
    "def recommend(id, num):\n",
    "    if (num == 0):\n",
    "        print(\"You haven't chosen a book dawg! I can't recommend anything if you didn't choose one.\")\n",
    "    elif (num==1):\n",
    "        print(\"Here is \" + str(num) + \" book similar to \" + item(id) + \":\")\n",
    "    else :\n",
    "        print(\"Here are \" + str(num) + \" books similar to \" + item(id) + \":\")\n",
    "        \n",
    "    print(\"----------------------------------------------------------\")\n",
    "    recs = results[id][:num]\n",
    "    for rec in recs:\n",
    "        print(item(rec[1]) + \" (score:\" + str(rec[0]) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 books similar to Python Machine Learning :\n",
      "----------------------------------------------------------\n",
      "Pattern Recognition and Machine Learning  (score:0.30466902859680617)\n",
      "Machine Learning :A Probablisitic Perspective (score:0.29088234870148644)\n",
      "Natural Langauage Processing with Python (score:0.1232123322436553)\n",
      "An introduction to Statistical Learning  (score:0.10186256812768607)\n",
      "The Elements of Statistical Learning  (score:0.09932294987882118)\n"
     ]
    }
   ],
   "source": [
    "recommend(7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
